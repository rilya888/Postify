# План: два тарифа подписки (текст / текст + аудио)

Версия: 1.0. Основа: ideal_platform_workflow.md, упрощённый скоуп: без видео/YouTube (на будущее). Актуальные модели OpenAI — по документации API на 2025 год.

---

## Скоуп

- **Включено сейчас:** два тарифа подписки; конвейер текст → (опционально аудио → транскрипт) → Normalize → Content Pack → Generate по платформам; кэш, разделение system/user, безопасные логи.
- **На будущее:** видео, YouTube, асинхронные джобы (GenerationJob), отдельный шаг Polish (LLM), Custom-тариф.

**Явные правила:**

- **Язык — из текста:** язык определять по контенту (детект для текста, ответ Whisper для аудио). Выбор пользователя — только опциональное переопределение.
- **Аудио удалять после транскрипции:** после успешной транскрипции удалять загруженный аудиофайл; хранить только Transcript в БД. Сырые аудиофайлы не хранить.

---

## Тарифы подписки

### Тариф 1 — «Текст» (Text)

- **Источник:** только текст (вставка или загрузка .txt).
- **Пайплайн:** Ingest текста → Normalize (опционально, простая очистка или LLM) → Content Pack (один раз) → Generate по платформам из Pack.
- **Модели OpenAI (актуальные):**
  - Content Pack / Normalize: `gpt-4.1-nano` или `gpt-5-nano` (структура, JSON).
  - Генерация постов: `gpt-4o-mini` или `gpt-5-mini` (дешевле), при необходимости `gpt-4o` / `gpt-4.1` (качество).
- **Лимиты:** max длина текста (символы/токены), max проектов, max outputs на проект, rate-limit запросов/час — в константах по плану (free/pro).

### Тариф 2 — «Текст + Аудио» (Text + Audio)

- Всё из тарифа 1 плюс:
- **Источник:** текст **или** загрузка аудиофайла (mp3, wav, m4a и т.д.).
- **Транскрипция:** OpenAI Audio API.
  - Модель по умолчанию: **`whisper-1`** (дёшево, достаточно для подкастов/интервью).
  - Опционально для тарифа Pro позже: **`gpt-4o-mini-transcribe`** или **`gpt-4o-transcribe`** (лучшая точность, несколько спикеров).
- **Пайплайн для аудио:** загрузка файла → извлечение аудио при необходимости (ffmpeg для видео-файлов с аудиодорожкой) → транскрипция (whisper-1) → сохранение rawTranscript + опционально normalizedTranscript → далее как текст: Normalize → Content Pack → Generate.
- **Хранение:** сущности `SourceAsset` (тип: text | audio) и `Transcript` (rawTranscript, normalizedTranscript, language, durationSeconds, transcriptionModel, costEstimate), связь с Project.
- **Лимиты:** max длительность аудио (минуты) на пользователя/месяц, max размер файла — задать в константах для тарифа 2.

Видео (в т.ч. YouTube) и разбор видео в этом плане **не делаем** — оставляем на будущее.

---

## Актуальные модели OpenAI (для конфига)

Использовать в коде только реальные идентификаторы из API:

- **Чат (текст):** `gpt-5-nano`, `gpt-5-mini`, `gpt-5.2`, `gpt-4.1-nano`, `gpt-4.1-mini`, `gpt-4.1`, `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`, `gpt-3.5-turbo`.
- **Транскрипция (аудио):** `whisper-1`, `gpt-4o-mini-transcribe`, `gpt-4o-transcribe`, `gpt-4o-transcribe-diarize`.

Рекомендуемый конфиг по этапам:

- **Normalize / Content Pack:** `gpt-4.1-nano` или `gpt-5-nano` (если доступны), иначе `gpt-4o-mini`.
- **Генерация постов (тариф «Текст»):** `gpt-4o-mini` или `gpt-5-mini`; при необходимости качества — `gpt-4o` или `gpt-4.1`.
- **Транскрипция (тариф «Текст + Аудио»):** `whisper-1`.

Конфиг вынести в константы (например `lib/constants/ai-models.ts`) с привязкой к типу подписки (plan: text | text_audio).

---

## Этапы реализации

### Этап 1. Фундамент (оба тарифа)

- Разделение **system / user** в вызовах OpenAI: короткий system (правила), user — задача + данные (сначала sourceContent, потом contentPack).
- **Детерминированный cacheKey** без `Date.now()`:  
  `sha256(userId + projectId + step + model + platform + hash(input) + hash(options) + brandVoiceId + brandVoiceUpdatedAt)`.  
  TTL: Content Pack 7–30 дней, Outputs 7–30 дней.
- **Brand Voice** через плейсхолдер `{brandVoice}` в шаблонах промптов.
- **Единый контур:** validate → sanitize → save → return для каждой генерации по платформе.
- **requestId** в API и логах; **не логировать** пользовательский контент (только длины, хэши, requestId, ошибки).

Файлы: `lib/ai/openai-client.ts`, `lib/services/ai.ts`, `lib/services/cache.ts`, `lib/utils/logger.ts`, шаблоны в `lib/ai/prompts/`.

---

### Этап 2. Content Pack и генерация из Pack (тариф «Текст»)

- Модель **ContentPack** в Prisma: projectId, userId, packJson (Json), inputHash (String), model, createdAt. Связь Project → ContentPack (один актуальный или по версиям по хэшу).
- **Источник текста для Pack:** единообразно: для проектов только с текстом — `project.sourceContent`; для проектов с аудио — текст из последнего `Transcript.normalizedTranscript` (или rawTranscript). В БД при загрузке аудио можно дублировать итоговый текст в `project.sourceContent` для совместимости списков и UI, либо хранить только в Transcript и в сервисе Pack брать «текст проекта» из Project или из Transcript по наличию.
- Сервис **Content Pack:** вход — текст (см. выше), опции (язык, brandVoiceId). **Язык — брать из текста:** определять язык по самому тексту (детект: библиотека или ответ Whisper/модели). Выбор языка пользователем — только опциональное переопределение; по умолчанию источник языка — текст (или транскрипт). Передавать определённый язык в промпт Pack. Один вызов модели (gpt-4.1-nano / gpt-5-nano / gpt-4o-mini), строгий JSON. Поля: summary_short, summary_long, key_points[], audience, tone_suggestions, quotes[], cta_options[], hashtags[], compliance_notes; опционально sections[], faq[].
- **Генерация постов:** вход модели — только Content Pack (JSON) + platformSpec + brandVoice, без длинного исходного текста. Промпты платформ переписать под приём `contentPack`.
- При первом Generate по проекту: построить Pack, сохранить в БД и кэш; дальше использовать его. Обратная совместимость: проекты без Pack — при следующем Generate построить Pack и перейти на новую схему.
- Параметры: temperature для Pack 0.0–0.2, max_tokens 800–1500; для постов — по платформе (LinkedIn 500–900, Email 800–1400 и т.д.), температура 0.7 (email 0.5–0.7).

Файлы: `prisma/schema.prisma`, новый `lib/services/content-pack.ts`, `lib/services/ai.ts`, промпты в `lib/ai/prompts/`.

---

### Этап 3. Подписки: тариф «Текст» vs «Текст + Аудио»

- В **Subscription** или константах планов: идентификатор плана **text** | **text_audio** (или маппинг legacy: free → text, pro/enterprise → text_audio до введения отдельного поля planType).
- **Лимиты по планам:** max проектов, max длина текста (символы), max outputs на проект, rate-limit (запросов/час). Для **text_audio** дополнительно: max минут аудио в месяц, max размер аудиофайла (MB).
- **Учёт минут аудио (тариф text_audio):** хранить использованные минуты за период (например таблица `Usage`: userId, periodStart, audioMinutesUsed, или поля в Subscription: audioMinutesUsedThisPeriod, audioMinutesLimit, periodEnd). При каждой успешной транскрипции увеличивать счётчик; при проверке лимита перед транскрипцией отклонять запрос при превышении. Сброс периода — по текущей логике подписки (currentPeriodEnd) или календарный месяц.
- Конфиг моделей: привязка к плану (text / text_audio). Для text_audio в UI показывать опцию «Загрузить аудио».
- Проверка при Generate и при загрузке аудио: если план text — не принимать аудио; если text_audio — разрешать и текст, и аудио.

Файлы: `lib/constants/plans.ts`, новый `lib/constants/ai-models.ts`, `lib/services/quota.ts`, API generate и upload (см. этап 4).

---

### Этап 4. Аудио Ingest (только тариф «Текст + Аудио»)

- **Загрузка файла:** API `POST /api/upload` или `POST /api/projects/[id]/ingest-audio`: принятие аудио (и при необходимости видео с аудиодорожкой). Лимиты: размер файла, длительность — по плану. **Аудио удалять после транскрипции:** после успешной транскрипции удалять загруженный аудиофайл с диска/хранилища; хранить только результат в БД (Transcript). Не хранить сырые аудиофайлы. В SourceAsset сохранять только метаданные (тип, длительность, язык, модель); fileUrlOrPath можно очищать или не сохранять после удаления файла.
- **Проверка до вызова Whisper:** проверить длительность и размер файла по лимитам плана и лимитам OpenAI API; при превышении вернуть 400 с понятным сообщением до загрузки в API.
- **Извлечение аудио:** для форматов с видео (например mp4) — ffmpeg на сервере, извлечь аудио в wav/mp3 для передачи в API.
- **Транскрипция:** OpenAI Audio API, модель **`whisper-1`**. Параметры: language (auto или от пользователя), response_format text. Результат — rawTranscript. **Ошибки:** при таймауте/rate limit — повтор с backoff (1–2 раза); при неуспехе — сохранить статус ошибки в Transcript или в ответе, показать пользователю сообщение и возможность повторной загрузки/повтора.
- **Сущности БД:**
  - **SourceAsset:** id, projectId, userId, type (text | audio), fileUrlOrPath (nullable), durationSeconds (nullable), createdAt.
  - **Transcript:** id, sourceAssetId, rawTranscript (Text), normalizedTranscript (Text, nullable), language, durationSeconds, transcriptionModel, costEstimate (nullable), **status** (pending | in_progress | completed | failed), createdAt.  
  Связь: Project has many SourceAsset; SourceAsset has one Transcript (после транскрипции). Статус транскрипции — для отображения в UI и повторных попыток.
- **Нормализация транскрипта:** простая очистка (пробелы, переносы) или опционально вызов дешёвой модели — результат в normalizedTranscript. Далее конвейер: normalizedTranscript → Content Pack → Generate (как для текста).
- **Язык из текста:** при Ingest текста — определять язык по контенту (детект); при аудио — язык в ответе Whisper. Сохранять в Transcript/Project и передавать в Content Pack. Выбор пользователя — только переопределение.

Файлы: `prisma/schema.prisma`, новый `app/api/upload/route.ts` или `app/api/projects/[id]/ingest-audio/route.ts`, новый `lib/services/transcription.ts` (или `lib/services/ingest-audio.ts`), вызов в создании/редактировании проекта или отдельный шаг «Добавить аудио».

---

### Этап 5. Конфиг моделей и параметры генерации

- Файл **`lib/constants/ai-models.ts`** (или расширить `lib/constants/plans.ts`):
  - Модели по этапам: normalize, contentPack, generate (по умолчанию для каждого плана).
  - Для плана text: contentPack = gpt-4.1-nano | gpt-5-nano | gpt-4o-mini; generate = gpt-4o-mini | gpt-5-mini.
  - Для плана text_audio: те же + transcription = whisper-1.
- Параметры генерации по плану (раздел 4 ideal_platform_workflow): температура (посты 0.7, email 0.5–0.7, JSON 0.0–0.2), max_tokens по платформе (LinkedIn 500–900, Email 800–1400, Content Pack 800–1500). Вынести в константы и использовать в вызовах.
- Во всех вызовах (normalize, content pack, generate) брать модель из конфига по плану пользователя, а не хардкод.

---

### Этап 6. Версионирование и метаданные

- При каждой успешной **regenerate** сохранять текущий content в **OutputVersion** перед записью нового (как при ручном редактировании).
- **generationMetadata:** model, temperature, maxTokens, timestamp, tokensUsed (если API отдаёт), costEstimate (по тарифам OpenAI), latencyMs, seed (если есть). Хранить в Output и дублировать в OutputVersion при создании снимка.

Файлы: `lib/services/ai.ts`, `lib/services/editor.ts`.

---

### Этап 7. UX: выбор тарифа и типа источника

- В настройках подписки или при создании проекта: явное отображение тарифа (**Текст** / **Текст + Аудио**). Для **Текст + Аудио** — блок «Загрузить аудио» (кнопка выбора файла, лимиты по длительности/размеру).
- **Тариф «Текст»:** кроме вставки текста вручную — опция загрузки .txt-файла (API или UI): извлечь текст и подставить в sourceContent (то же поле, что и при вставке).
- После загрузки аудио: показ статуса «Транскрипция…», затем отображение текста транскрипта и кнопка «Сгенерировать посты» (как для текстового проекта). При ошибке транскрипции — сообщение и кнопка «Повторить» или «Загрузить другой файл».
- Язык контента: по умолчанию берётся из текста (детект) или из транскрипта (Whisper); выбор пользователя — опциональное переопределение. Brand Voice и платформы — без изменений относительно текущего поведения.

---

## Порядок внедрения

1. Этап 1 — кэш, system/user, brandVoice, логи (фундамент).
2. Этап 2 — Content Pack и генерация из Pack (тариф «Текст»).
3. Этап 5 — конфиг моделей и параметры (можно частично параллельно с этапом 2).
4. Этап 3 — два плана подписки и лимиты.
5. Этап 4 — аудио Ingest и транскрипция (тариф «Текст + Аудио»).
6. Этап 6 — версионирование на каждую regenerate.
7. Этап 7 — UX выбора тарифа и загрузки аудио.

---

## Что явно не входит в этот план (на будущее)

- Видео, YouTube, разбор видео.
- Асинхронные джобы (GenerationJob) и API по jobId.
- Отдельный шаг Polish (LLM).
- Тариф Custom (выбор модели по этапам, приоритетная очередь).
- Redis/Upstash для rate limit (пока можно in-memory с документированием ограничения).

---

## Дополнения к плану (после повторного просмотра)

- **Миграции Prisma:** для ContentPack, SourceAsset, Transcript (и при необходимости Usage / поля Subscription для минут аудио) — отдельные миграции с сохранением обратной совместимости: существующие Project/Output без изменений, новые поля опциональны или с default.
- **Fallback-модель:** в `lib/ai/openai-client.ts` оставить или добавить fallback при недоступности основной модели (например gpt-4o-mini → gpt-3.5-turbo) для генерации постов, чтобы сервис не падал при сбоях API.
- **Защита от дорогих запросов (по документу 6.2):** если текст/транскрипт очень длинный (например > X токенов) — принудительно сначала строить Content Pack, затем генерация по платформам; при большом числе платформ — ограничить concurrency (очередь до K параллельных вызовов), чтобы не упираться в rate limit.
- **PII (по документу 7.3):** опционально на текущем скоупе: простая проверка на email/телефон/адрес (regex) в тексте или в транскрипте перед/после Pack; при обнаружении — предупреждение в UI и возможность редактирования. Не блокировать генерацию.
- **Тесты:** добавить или расширить тесты: (1) Content Pack — мок OpenAI, проверка формата JSON и полей; (2) транскрипция — мок Whisper API, проверка сохранения Transcript; (3) лимиты плана — проверка, что тариф text не принимает аудио и что text_audio проверяет лимит минут.

**Из IMPLEMENTATION_PLAN_qwen.md:**

- **Нормализация как отдельный сервис (опционально):** вынести очистку текста и детект языка в `lib/services/normalization.ts` (очистка от «эээ», таймкодов, сегментация, тема/аудитория). В текущем скоупе можно вызывать из content-pack или ingest; при росте логики — отдельный модуль.
- **Эндпоинты API:** при необходимости явно выделить маршруты: `/api/ingest` (приём текста/файла), `/api/content-pack` (создание/получение Pack по projectId), `/api/transcribe` (запуск транскрипции аудио). Сейчас можно совместить с `/api/generate` и upload; при разделении фронта — добавить эти эндпоинты.
- **Повтор с exponential backoff:** для всех вызовов внешнего API (OpenAI: generate, Pack, Whisper) — повтор при временных ошибках с экспоненциальной задержкой (1s, 2s, 4s). Сейчас частично есть в openai-client; распространить на транскрипцию и Pack.
- **Инвалидация кэша:** при изменении исходного текста проекта или смене brand voice — инвалидировать кэш Pack и outputs по этому проекту (удалить ключи или сбросить TTL), чтобы следующая генерация не брала устаревший результат из кэша.
- **Учёт стоимости по операциям:** хранить costEstimate в Transcript и в generationMetadata Output; при необходимости — отдельный учёт (таблица или агрегат по userId/period) для отчётов и лимитов по себестоимости (по мотивам qwen Phase 6).
- **Миграция для существующих пользователей:** краткий чек-лист или раздел в документации: как ведут себя старые проекты при переходе на Pack (первый Generate строит Pack), как маппить free/pro на text/text_audio, что делать с уже сгенерированными outputs.

Этот план задаёт обновлённый, сфокусированный объём: два тарифа (текст; текст + аудио через Whisper) и актуальные модели OpenAI.

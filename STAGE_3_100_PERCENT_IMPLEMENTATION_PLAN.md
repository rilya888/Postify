# План реализации этапа 3 на 100%

Цель: закрыть все пункты [STAGE_3_DETAILED_PLAN.md](../STAGES/STAGE_3_DETAILED_PLAN.md), опираясь на [STAGE_3_PLAN_VS_IMPLEMENTATION.md](STAGE_3_PLAN_VS_IMPLEMENTATION.md). Ниже только то, что ещё не сделано.

---

## Приоритет 1 — Обязательно для 100%

### 1. Отмена генерации (День 10-11 плана)
- **Задачи:**
  - На странице [app/(dashboard)/projects/[id]/generate/page.tsx](app/(dashboard)/projects/[id]/generate/page.tsx) при вызове `fetch('/api/generate')` создать `AbortController`, передать `signal` в `fetch(..., { signal })`.
  - Добавить кнопку «Cancel» рядом с «Generating...», по клику вызывать `controller.abort()`.
  - В обработчике ответа: при `err.name === 'AbortError'` сбрасывать loading, показывать toast «Generation cancelled», не показывать ошибку.
  - Убедиться, что при повторном нажатии «Generate» создаётся новый controller (не переиспользовать отменённый).

### 2. Кнопки перехода к редактированию (День 12-13 плана)
- **Задачи:**
  - В [components/ai/generated-content-preview.tsx](components/ai/generated-content-preview.tsx) добавить опциональный проп `editHref?: string` или передавать `actions` снаружи.
  - На странице генерации в блоке результатов и в «Previously Generated Content» добавить кнопку «Edit» рядом с Regenerate (или в `actions`), ведущую на маршрут редактирования output.
  - Маршрут редактирования: если в рамках этапа 4 — использовать заглушку (например, ссылка на `/projects/[id]/edit` с query `?outputId=...` или будущий `/projects/[id]/outputs/[outputId]/edit`). В плане указано «будет использоваться в Этапе 4», достаточно заглушки/ссылки.

### 3. Система тестирования промптов (День 3-4 плана)
- **Задачи:**
  - Создать скрипт или набор тестов (например, в `__tests__/prompts/` или `scripts/test-prompts.ts`), который:
    - Для каждой платформы подставляет тестовый `sourceContent` в шаблон через `formatPrompt` / `getPlatformPromptTemplate`.
    - Проверяет, что в результате нет плейсхолдера `{sourceContent}` и что длина/формат строки ожидаемые (без вызова OpenAI).
  - Либо оформить как unit-тест (Jest/Vitest): вызов `getPlatformPromptTemplate`, `formatPrompt`, проверка что вывод содержит исходный контент и не содержит `{sourceContent}`.

### 4. Unit-тесты (День 14-15 и раздел «Тестирование»)
- **Задачи:**
  - Подключить Jest или Vitest в проекте (если ещё нет), настроить для TypeScript и путей `@/`.
  - **OpenAI-клиент:** тесты с моком `openai.chat.completions.create`: проверка вызова с правильными `model`, `messages`, `temperature`, `max_tokens`; при ошибке — повторные вызовы (retry).
  - **Сервис AI:** моки `prisma`, `generateContentWithRetry`, `checkProjectQuota`, `logProjectChange`; тест `generateForPlatforms`: при успехе — вызов upsert и logProjectChange; при превышении квоты — throw.
  - **Валидация контента:** тесты для `validateContentLength`, `sanitizeContent`, `validatePlatformContent` (граничные значения длины, запрещённые теги).
  - **Промпты:** см. п.3 (система тестирования промптов).

### 5. Интеграционные тесты (раздел «Тестирование»)
- **Задачи:**
  - Тест POST `/api/generate`: с моком сессии (auth) и моком `generateForPlatforms`; проверка 401 без сессии, 400 при пустом sourceContent/невалидных platforms, 200 и структуры ответа при успехе, 429 при превышении rate limit (если мокаем rate-limit).
  - Тест «сохранение в БД»: вызов `generateForPlatforms` с моком OpenAI; проверка, что в БД создаётся/обновляется запись Output и запись в ProjectHistory (можно через тестовую БД или мок Prisma).

### 6. E2E-тесты (раздел «Тестирование»)
- **Задачи:**
  - Подключить Playwright или Cypress (если ещё нет).
  - Сценарий: авторизация (или мок сессии) → переход на страницу генерации проекта → выбор платформ → нажатие «Generate» → ожидание появления блока результатов или сообщения об ошибке.
  - Для стабильности можно мокать `fetch('/api/generate')` в E2E или использовать тестовый бэкенд.

---

## Приоритет 2 — Критерии плана (минимальная реализация)

### 7. Кэширование результатов (День 12-13 плана)
- **Задачи:**
  - Вариант A: перед вызовом OpenAI в `generateForPlatforms` проверять, есть ли уже Output для данной пары (projectId, platform) с тем же хешем sourceContent (или без проверки хеша — просто «если уже есть output для этих платформ, не перезаписывать без явного regenerate»). В текущей логике повторный запуск уже перезаписывает через upsert; «кэш» можно трактовать как «не вызывать AI, если для projectId+platform уже есть свежий output» — тогда добавить опцию или флаг.
  - Вариант B (простой): в памяти API (Map) кэшировать результат по ключу `projectId:platforms:hash(sourceContent)` на 5–10 минут; при совпадении ключа возвращать сохранённый результат без вызова OpenAI. Учесть инвалидацию при обновлении проекта.
  - Выбрать один вариант и реализовать; документировать в API.md.

### 8. Метрики использования AI (День 12-13 и раздел «Мониторинг»)
- **Задачи:**
  - Сохранять в `generationMetadata` время выполнения генерации (start/end или duration ms) — если ещё не сохраняется.
  - Опционально: таблица или сервис `ai_usage` (userId, date, successCount, failCount, totalTokens или вызовов); запись после каждой генерации. Либо ограничиться логированием структурированных полей (userId, projectId, successful, failed, duration) для последующего разбора в логах.
  - Документировать, какие метрики доступны и где их смотреть.

### 9. Алертинг (раздел «Мониторинг»)
- **Задачи:**
  - Минимум: описать в документации (например, в docs/API.md или STAGE_3_IMPLEMENTATION_README), при каких условиях смотреть логи (частые 429, рост 5xx, ошибки OpenAI) и что делать.
  - По желанию: интеграция с Sentry (или аналог) на ошибках в `/api/generate` и в `generateForPlatforms` с передачей контекста (без PII).

---

## Приоритет 3 — Опционально по плану

### 10. Модерация контента перед сохранением (раздел «Безопасность»)
- **Задачи:**
  - Добавить опциональный шаг перед сохранением Output: вызов внешнего сервиса модерации или проверка по списку запрещённых фраз; при «reject» не сохранять контент, вернуть ошибку пользователю.
  - Либо задокументировать как будущее расширение и оставить заглушку (функция `moderateContent(content): Promise<{ allowed: boolean }>` с возвратом `{ allowed: true }`).

### 11. Производительность: пул соединений, lazy loading (раздел «Производительность»)
- **Задачи:**
  - Пул соединений с OpenAI: официальный SDK обычно сам управляет соединениями; зафиксировать в документации, что пул не настраивается отдельно, либо исследовать опции `openai` и при необходимости вынести клиент в синглтон (уже есть getOpenAIClient).
  - Lazy loading результатов генерации: на странице генерации при большом числе outputs подгружать «Previously Generated» по скроллу или по кнопке «Show more» (пагинация по outputs). Оценка: нужен ли при текущем лимите outputs на проект (1–10) — при необходимости реализовать.

### 12. I18N (раздел «Интернационализация»)
- **Задачи:**
  - В плане помечено отдельным блоком; для 100% по этапу 3 достаточно задокументировать: «I18N запланирован на отдельный этап; промпты и сообщения об ошибках пока на одном языке (русский/английский)».
  - Либо минимальная подготовка: вынести строки ошибок и подписей кнопок в константы/файлы локалей без смены языка в UI.

### 13. Резервные механизмы и восстановление (раздел «Планирование на будущее»)
- **Задачи:**
  - Документировать в архитектурном документе или в STAGE_3_IMPLEMENTATION_README: резервная модель при недоступности OpenAI, локальное кэширование для восстановления, откат промптов — планируются на пост-MVP.
  - При желании: при ошибке OpenAI логировать «fallback unavailable» и оставлять поведение «throw» как есть.

---

## Порядок выполнения

1. **Приоритет 1:** п.1 (отмена генерации) → п.2 (кнопки Edit) → п.3 (тестирование промптов) → п.4 (unit-тесты) → п.5 (интеграционные тесты) → п.6 (E2E).
2. **Приоритет 2:** п.7 (кэширование) → п.8 (метрики) → п.9 (алертинг).
3. **Приоритет 3:** по необходимости — п.10–13 (модерация, производительность, I18N, резервные механизмы).

После выполнения пунктов приоритета 1 и 2 этап 3 считается выполненным на 100% по чек-листу плана; приоритет 3 можно закрывать минимально (документация и заглушки) или переносить на следующий этап.

---

## Чек-лист для приёмки 100%

- [ ] Отмена генерации (AbortController + кнопка Cancel).
- [ ] Кнопки перехода к редактированию (хотя бы заглушки на этап 4).
- [ ] Система тестирования промптов (скрипт или unit-тесты подстановки).
- [ ] Unit-тесты: openai-client, ai service, content-validation, промпты.
- [ ] Интеграционные тесты: API generate, сохранение в БД.
- [ ] E2E: сценарий генерации (или мок API).
- [ ] Кэширование: реализовано или явно отложено с документированием.
- [ ] Метрики AI: в метаданных или отдельно, документированы.
- [ ] Алертинг: описан в документации или интеграция с Sentry.
- [ ] Модерация / I18N / резервные механизмы: либо минимальная реализация, либо явно отложены в документации.

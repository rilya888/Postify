# Идеальная модель работы платформы (статья/подкаст/видео → посты)

Версия: 1.0 (2026-02-04)

Цель: максимальное качество **при минимальной себестоимости**, предсказуемое поведение генераций, масштабирование без сюрпризов.

> Документ написан под твой текущий стек: Next.js (App Router) + NextAuth + Prisma + OpenAI API. Он предполагает, что сейчас у тебя генерация идёт «по платформам» и в коде по умолчанию стоит `gpt-4-turbo`. Ниже — как сделать «идеально»: дешево, быстро, качественно и устойчиво.

---

## 1) Главный принцип экономии

**Никогда не кормим модель одним и тем же большим источником N раз.**

Вместо этого строим конвейер:

1) **Ingest**: получаем текст (или транскрипт).
2) **Normalize**: чистим/структурируем.
3) **Content Pack** (один раз): делаем компактный «пакет знаний» (JSON).
4) **Generate outputs** (N раз): генерируем посты, опираясь на Content Pack.
5) **Polish/Validate** (по желанию): дешёвый проход на проверку формата/длины/тона.

**Суть:** большой текст → один раз → короткий JSON → много выходов.

---

## 2) Модели и роли (идеальная раскладка)

Ниже — логика выбора моделей «по ролям», а не «одна модель на всё».

### 2.1 Транскрипция (аудио/видео → текст)

Транскрипция — отдельный тарифный слой (можно вынести как add‑on к подписке).

### Standard (дёшево и быстро)
**Модель:** `whisper-1`

Использовать когда:
- подкасты, интервью, YouTube-видео с нормальным звуком
- нет сильного шума
- один или два спикера

Рекомендуемые настройки:
- language: auto (или вручную выбранный пользователем)
- timestamps: off (включать только если нужны клипы)
- diarization: off

Плюсы:
- самая низкая цена
- достаточно хорошее качество для контент‑репёрпосинга

Минусы:
- хуже справляется с шумом и несколькими спикерами

---

### Pro (максимальная точность)
**Модель:** `gpt-4o-mini-transcribe` (или `gpt-4o-transcribe` при максимальных требованиях)

Использовать когда:
- плохой звук
- несколько говорящих
- важна точность формулировок (образовательный, юридический, бизнес‑контент)

Рекомендуемые настройки:
- language: явно задан
- timestamps: on
- diarization: on

Плюсы:
- лучшая точность
- корректная сегментация спикеров
- меньше мусора в тексте

Минусы:
- дороже Whisper

---

### Логика выбора модели

По умолчанию → `whisper-1`

Переключение на Pro, если:
- пользователь выбрал режим Pro
- длительность > X минут И качество важно
- аудио определено как шумное (опционально авто‑детект)

---

### Хранение результата транскрипции

В БД сохранять:
- rawTranscript
- normalizedTranscript
- language
- durationSeconds
- transcriptionModel
- costEstimate

---

## 2.2 «Техничка/структура» (дёшево)
 «Техничка/структура» (дёшево)
Используется для:
- очистки текста
- сегментации
- извлечения тезисов
- JSON-структур

**Default:** `gpt-4.1-nano`

**Если нужно лучше:** `gpt-4.1-mini`

### 2.3 «Писатель/копирайт» (основной генератор)
Используется для:
- готовых постов, писем, описаний
- разных тонов/стилей

**Default:** `gpt-5-mini` (или альтернативно `gpt-4.1-mini`, если хочешь стабильную линию 4.1)

**Premium:** `gpt-5.1` / `gpt-5.2` — для тарифа Pro (лучший стиль, сложные инструкции, 3 варианта, более «человечно»)

### 2.4 «Проверяющий/полировка» (почти бесплатно)
Используется для:
- проверки лимитов (длина, структура)
- грамматики
- соответствия brand voice
- удаления воды

**Default:** `gpt-4.1-nano`

---

## 3) Пайплайн: энд-ту-энд (идеальный)

### Шаг 0 — Ввод пользователя
Пользователь выбирает:
- источник: **текст** / **файл** / **YouTube ссылка** / **аудио/видео upload**
- язык
- тон бренда (brand voice) или выбор пресета
- платформы для выхода (LinkedIn, Email, IG, TikTok, YouTube и т.д.)
- режим качества: **Standard** / **Pro**

### Шаг 1 — Ingest (получить текст)

#### 1A) Текст/файл
- извлечь текст
- нормализовать пробелы/переносы
- детект языка

#### 1B) YouTube ссылка
**Рекомендованный безопасный UX:**
- попытаться использовать **субтитры**, если доступны
- если нет субтитров/нет доступа: попросить пользователя загрузить файл (или дать свой исходник)

#### 1C) Видео/аудио upload
- извлечь аудио (ffmpeg на сервере)
- транскрибировать (`whisper-1` или transcribe-модель)

### Шаг 2 — Normalize (очистка и сегментация)
Модель: `gpt-4.1-nano`

Цели:
- убрать мусор: таймкоды (если не нужны), повторяющиеся фразы, «эээ», «ну»
- привести к читаемой структуре
- определить тему, аудиторию, ключевые блоки

**Выход:** `normalizedText` (текст) + `docMeta` (JSON: язык, тема, аудитория)

### Шаг 3 — Content Pack (один раз на источник)
Модель: `gpt-4.1-nano` (или `gpt-4.1-mini` для сложных тем)

**Content Pack (JSON) — обязательные поля:**
- `summary_short` (5–7 строк)
- `summary_long` (12–20 строк)
- `key_points[]` (10–25 пунктов)
- `audience` (кто читатель)
- `tone_suggestions` (как звучать)
- `quotes[]` (5–15 цитат/фактов)
- `cta_options[]` (3–8 призывов к действию)
- `hashtags[]` (если релевантно)
- `compliance_notes` (если есть риски: мед/финансы/юриспруденция)

**Опционально, но очень полезно:**
- `sections[]` (главы/блоки)
- `faq[]` (возможные вопросы)
- `clip_markers[]` (если есть таймкоды: «лучшие моменты»)

### Шаг 4 — Generate Outputs (N выходов)
Модель: `gpt-5-mini` (Standard) / `gpt-5.2` (Pro)

**Вход на генерацию поста =**
- короткий system (правила качества)
- `platformSpec` (конкретные требования LinkedIn/Email)
- `brandVoice` (правила бренда)
- `contentPack` (JSON)

**Важно:** исходный длинный текст *не передавать* на этом шаге.

### Шаг 5 — Polish & Validate (опционально)
Модель: `gpt-4.1-nano`

Проверки:
- длина по лимитам (символы/слова)
- структура (заголовок, буллеты, CTA)
- запреты (PII, запрещённые темы, токсичность)
- соблюдение brand voice

**Выход:** финальный текст + отчёт валидации (JSON)

### Шаг 6 — Версионирование и история
- сохранять `OutputVersion` на каждую regenerate
- хранить `generationMetadata`: модель, токены, температура, seed (если доступно), время

---

## 4) Настройки генерации (рекомендуемые дефолты)

### 4.1 Температура
- Standard посты: `temperature = 0.7`
- Email (чуть аккуратнее): `temperature = 0.5–0.7`
- Strict формат/JSON: `temperature = 0.0–0.2`

### 4.2 Max tokens
- LinkedIn пост: `max_output_tokens = 500–900`
- Email: `max_output_tokens = 800–1400`
- Content Pack JSON: `max_output_tokens = 800–1500` (зависит от глубины)

### 4.3 Формат вывода
- Для Content Pack: **строгий JSON** (структурированный вывод)
- Для постов: текст + опционально мини-JSON с метаданными (например, `title`, `hashtags`, `cta`)

### 4.4 Один вызов vs несколько
**Идеально:** генерировать все нужные форматы **за 1–2 вызова**, но:
- если платформы сильно разные, лучше 1 вызов = 1 платформа (но с Content Pack, чтобы вход был маленький)
- если нужно экономить latency: параллелить по платформам

---

## 5) Кэширование (обязательно для низкой себестоимости)

### 5.1 Что кэшировать
1) Content Pack (по хэшу normalizedText + brandVoiceVersion)
2) Выходы по платформам (по хэшу contentPack + platformSpec + brandVoice + options)
3) «Polish» результаты (по хэшу финального текста + правила)

### 5.2 Детерминированный cacheKey
Ключ **не должен** содержать `Date.now()`.

Рекомендуемый ключ:
- `sha256(userId + projectId + step + model + platform + hash(input) + hash(options) + brandVoiceId + brandVoiceUpdatedAt)`

### 5.3 TTL
- Content Pack: 7–30 дней
- Outputs: 7–30 дней
- Polish: 1–7 дней

---

## 6) Лимиты и тарифы (чтобы не улететь в минус)

### 6.1 Ограничения по планам
- max длительность аудио/видео (мин)
- max размер текста (символы/токены)
- max outputs per project
- rate-limit per user (запросов/час)

### 6.2 Защита от «дорогих» запросов
- если transcript > X токенов → сначала `contentPack` на nano
- если пользователь просит 10 платформ → сначала «пакет», затем очередями
- если “Pro”: разрешить дорогие модели, но ограничить количество regenerate

---

## 7) Безопасность и соответствие

### 7.1 Нельзя логировать пользовательский контент
В логах хранить:
- длины
- хэши
- requestId
- ошибки

### 7.2 System vs User
- system: короткие правила (без длинного исходника)
- user: конкретная задача + contentPack

### 7.3 PII и чувствительный контент
- добавить проверку на PII (email/телефон/адрес) на шаге Normalize/Polish
- предупреждать пользователя и предлагать редактирование

---

## 8) Идеальная структура данных (Prisma)

### 8.1 Добавить сущности
- `SourceAsset` (ссылка/файл, тип, длительность, язык)
- `Transcript` (сырой, нормализованный, метаданные)
- `ContentPack` (JSON + hash + version)
- `GenerationJob` (для асинхронной очереди, статусы)

### 8.2 Output
- `Output` (актуальная версия)
- `OutputVersion` (история)
- `generationMetadata` (model, tokens, costEstimate, latency)

---

## 9) UX: как это выглядит для пользователя

### Режим Standard
1) вставил текст/ссылку/загрузил файл
2) выбрал платформы
3) нажал Generate
4) получил посты (быстро)

### Режим Pro
- доп. переключатели:
  - «High accuracy transcription»
  - «3 варианта на платформу»
  - «Глубокая адаптация brand voice»
  - «Сохранить стиль автора»

---

## 10) Оценка себестоимости (логика, а не конкретные цифры)

Себестоимость =
- транскрипция (по минутам)
- + Content Pack (один запрос дешёвой модели)
- + outputs (N запросов средней модели с маленьким входом)
- + polish (N дешёвых)

**Ключ к низкой цене:**
- не слать большой текст много раз
- хранить contentPack
- кэшировать outputs

---

## 11) Изменения в текущем коде (точечный чек-лист)

1) **Разнести system/user** и убрать дублирование sourceContent.
2) Исправить вставку Brand Voice через плейсхолдер `{brandVoice}`.
3) Сделать единый пайплайн: validate → sanitize → save → return.
4) Убрать `Date.now()` из cacheKey, сделать sha256.
5) Добавить шаг Content Pack и перевод генерации постов на contentPack.
6) Добавить requestId и redaction логов.
7) Усилить rate limit (Redis/Upstash или транзакционные квоты БД).

---

## 12) «Идеальные дефолты» (готовая конфигурация)

### Standard (дёшево и масштабируемо)
- Transcription: `whisper-1`
- Normalize: `gpt-4.1-nano`
- ContentPack: `gpt-4.1-nano`
- Outputs: `gpt-5-mini` (или `gpt-4.1-mini`)
- Polish: `gpt-4.1-nano`

Ориентир: минимальная себестоимость + хорошее качество для большинства кейсов.

---

### Pro (премиум качество)
- Transcription: `gpt-4o-mini-transcribe` (или `gpt-4o-transcribe`)
- Normalize: `gpt-4.1-mini`
- ContentPack: `gpt-4.1-mini`
- Outputs: `gpt-5.2`
- Polish: `gpt-4.1-nano`

Ориентир: максимальная точность речи + лучший стиль текста.

---

### Custom (для корпоративных клиентов)
- выбор модели на каждом этапе
- лимиты по длительности и объёму текста
- приоритетная очередь генераций

---

## 13) Подписки и add‑ons (рекомендуемая логика монетизации)

### Включено в Standard
- whisper-1 транскрипция до лимита минут
- генерация постов через mini‑модели

### Включено в Pro
- high‑accuracy транскрипция
- лучшие генеративные модели
- несколько вариантов постов

### Add‑ons
- дополнительные минуты транскрипции
- дополнительные regenerate
- ultra‑quality mode

---

## 14) Проверка качества (минимальный QA)

- Golden tests: 5–10 эталонных источников
- Проверять:
  - корректность транскрипции
  - сохранение фактов
  - стиль бренда
  - длину постов

---

## 15) Итог

Эта модель даёт:
- контролируемую себестоимость
- масштабируемость
- понятную монетизацию
- стабильное качество контента

Главный принцип — большой источник обрабатывается один раз, дальше работает компактный Content Pack.

